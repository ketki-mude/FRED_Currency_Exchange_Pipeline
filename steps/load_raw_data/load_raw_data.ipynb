{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "--!jinja\n",
    "ENV = '{{ env }}'\n",
    "print(\"Running notebook in environment:\", ENV)\n",
    "\n",
    "# Optionally, set the session variable so subsequent SQL statements in the notebook can use it.\n",
    "from snowflake.snowpark import Session\n",
    "session = Session.get_active_session()\n",
    "session.sql(f\"ALTER SESSION SET ENV = '{ENV}'\").collect()\n",
    "\n",
    "DB_NAME = \"FRED_DB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Use RAW_DAILY for both staging and tables\n",
    "\n",
    "TARGET_SCHEMA = f\"{ENV}_RAW_SCHEMA\"\n",
    " \n",
    "# S3 paths for the CSV files\n",
    "\n",
    "STAGES = {\n",
    "\n",
    "    \"DAILYCURRENCY_RAW_STAGE\": \"s3://fredcurrencyexhange/DailyCurrencyExchange/\",\n",
    "\n",
    "    \"MONTHLYCURRENCYEXCHANGE_RAW_STAGE\": \"s3://fredcurrencyexhange/MonthlyCurrencyExchange/\"\n",
    "\n",
    "}\n",
    " \n",
    "# Create the target schema if it doesn't exist\n",
    "\n",
    "session.sql(f\"CREATE SCHEMA IF NOT EXISTS {DB_NAME}.{TARGET_SCHEMA}\").collect()\n",
    "\n",
    "print(f\"‚úÖ Schema created/verified for {TARGET_SCHEMA} environment\")\n",
    " \n",
    "# Create CSV file format in the target schema\n",
    "\n",
    "create_file_format_sql = f\"\"\"\n",
    "\n",
    "CREATE OR REPLACE FILE FORMAT {TARGET_SCHEMA}.CSV_FORMAT\n",
    "\n",
    "    TYPE = 'CSV'\n",
    "\n",
    "    FIELD_DELIMITER = ','\n",
    "\n",
    "    PARSE_HEADER = TRUE\n",
    "\n",
    "    SKIP_BLANK_LINES = TRUE\n",
    "\n",
    "    TRIM_SPACE = TRUE\n",
    "\n",
    "    ENCODING = 'UTF-8'\n",
    "\n",
    "    NULL_IF = ('.', 'NULL', 'null', '');\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "session.sql(create_file_format_sql).collect()\n",
    "\n",
    "print(\"‚úÖ Created/Verified CSV file format in\", TARGET_SCHEMA)\n",
    " \n",
    "# Create external stages in the target schema (directly loading from S3)\n",
    "\n",
    "for stage, s3_path in STAGES.items():\n",
    "\n",
    "    create_stage_sql = f\"\"\"\n",
    "\n",
    "    CREATE OR REPLACE STAGE {TARGET_SCHEMA}.{stage}\n",
    "\n",
    "    STORAGE_INTEGRATION = fred_s3_integration\n",
    "\n",
    "    URL = '{s3_path}'\n",
    "\n",
    "    FILE_FORMAT = {TARGET_SCHEMA}.CSV_FORMAT;\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    session.sql(create_stage_sql).collect()\n",
    "\n",
    "    print(f\"‚úÖ Created/Verified stage: {stage} in {TARGET_SCHEMA}\")\n",
    " \n",
    "print(\"üîÑ Snowflake stages setup completed.\")\n",
    " \n",
    "# List files in the stages and load them into tables (all in TARGET_SCHEMA)\n",
    "\n",
    "for stage in STAGES:\n",
    "\n",
    "    print(f\"\\nüìÅ Files in {stage}:\")\n",
    "\n",
    "    list_files_sql = f\"LIST @{TARGET_SCHEMA}.{stage};\"\n",
    "\n",
    "    files = session.sql(list_files_sql).collect()\n",
    "\n",
    "    if not files:\n",
    "\n",
    "        print(\"  No files found in stage.\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        for file in files:\n",
    "\n",
    "            file_path = file[0]  # Full file path in S3\n",
    "\n",
    "            file_size = file[1]  # File size in bytes\n",
    "\n",
    "            file_name = os.path.basename(file_path)  # Extract just the file name\n",
    "\n",
    "            print(f\"  {file_path} (Size: {file_size} bytes)\")\n",
    "\n",
    "            # Generate table name (upper-case, without extension)\n",
    "\n",
    "            table_name = file_name.split(\".\")[0].upper()\n",
    "\n",
    "            # Create table in the TARGET_SCHEMA\n",
    "\n",
    "            create_table_sql = f\"\"\"\n",
    "\n",
    "            CREATE OR REPLACE TABLE {DB_NAME}.{TARGET_SCHEMA}.{table_name} (\n",
    "\n",
    "                DATE DATE,\n",
    "\n",
    "                VALUE FLOAT\n",
    "\n",
    "            );\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            session.sql(create_table_sql).collect()\n",
    "\n",
    "            print(f\"‚úÖ Created table: {table_name} in {TARGET_SCHEMA}\")\n",
    " \n",
    "            # Load data from the S3 stage into the table\n",
    "\n",
    "            copy_into_sql = f\"\"\"\n",
    "\n",
    "            COPY INTO {DB_NAME}.{TARGET_SCHEMA}.{table_name} \n",
    "\n",
    "            FROM @{TARGET_SCHEMA}.{stage}/{file_name}\n",
    "\n",
    "            FILE_FORMAT = {TARGET_SCHEMA}.CSV_FORMAT\n",
    "\n",
    "            MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            session.sql(copy_into_sql).collect()\n",
    "\n",
    "            print(f\"‚úÖ Data loaded into {TARGET_SCHEMA}.{table_name}\")\n",
    " \n",
    "            # Update table to replace NULLs (from '.') with 0\n",
    "\n",
    "            update_sql = f\"\"\"\n",
    "\n",
    "            UPDATE {DB_NAME}.{TARGET_SCHEMA}.{table_name}\n",
    "\n",
    "            SET VALUE = 0\n",
    "\n",
    "            WHERE VALUE IS NULL;\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            session.sql(update_sql).collect()\n",
    "\n",
    "            print(f\"‚úÖ Updated {table_name}: replaced NULL with 0 in VALUE column\")\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
